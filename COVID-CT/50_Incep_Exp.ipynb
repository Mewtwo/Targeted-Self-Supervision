{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "50 Incep Exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwG2S40EGvtL"
      },
      "source": [
        "First step is to read, and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uyMaADtV-TD",
        "outputId": "1ada6d0c-5518-4060-bca5-88e44dbd70fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6OodPbwEdCv",
        "outputId": "0d2fcb90-8711-4ae5-8f51-8dec0bdb373a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#imports\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "\n",
        "# Import keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import models, layers, Input, regularizers\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWi1oI1oG7vQ"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/MRP/Covid-target/self/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM9lj0p-2ke1"
      },
      "source": [
        "#Toggles\n",
        "self_sup = True\n",
        "incep = True\n",
        "aug = True\n",
        "saves = False\n",
        "big_arch = 0\n",
        "self_frac = \"50\"\n",
        "file_name = \"50Exp2_full\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk4WjsvTHYPJ"
      },
      "source": [
        "start_time = time.clock()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxkxMXWnquWu"
      },
      "source": [
        "#I will try Inception, so change H,W\n",
        "if incep == True:\n",
        "    H=299\n",
        "    W=299\n",
        "else:\n",
        "    H=224\n",
        "    W=224\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDIVkQCU9fK1"
      },
      "source": [
        "#End of preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxzuHMpYGuSO",
        "outputId": "b3f22e9c-c804-4c87-b0cb-d58f5e740697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "if incep == True:\n",
        "    base_model = keras.applications.InceptionV3(\n",
        "        include_top = False,\n",
        "        weights = \"imagenet\")\n",
        "else:\n",
        "    base_model = keras.applications.DenseNet169(\n",
        "        include_top = False,\n",
        "        weights = \"imagenet\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZoDKuLUOs07"
      },
      "source": [
        "Next step is to load the pre-trained model, add our own dense layer on top, and train the dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62PZcaIaYcnr"
      },
      "source": [
        "if self_sup == True:\n",
        "    cp = ModelCheckpoint(filepath= file_name + '_run1.hdf5', verbose=1, monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltC7tTQ3_uVv",
        "outputId": "6e25a6ff-cda7-40c5-d5a8-9345985ce364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "if aug == True:\n",
        "    train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "                                                dtype='float64')\n",
        "\n",
        "    #on test, we do not augment, merely preprocess\n",
        "    test_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "                                                dtype='float64')\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        self_frac + 'train',\n",
        "        target_size = (W,H),\n",
        "        #batch_size = 32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        self_frac + 'test',\n",
        "        target_size = (W,H),\n",
        "        #batch_size = 16,\n",
        "        class_mode = 'categorical'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 544 images belonging to 2 classes.\n",
            "Found 204 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TprHVnfLOrpN",
        "outputId": "929895aa-7ec1-4da1-bb15-968bc110ecd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#no fine tuning\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "if big_arch == 1:\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(1024, activation = 'relu', kernel_regularizer = regularizers.l2(0.01),)(x) \n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(1024, activation = 'relu', kernel_regularizer = regularizers.l2(0.01),)(x) \n",
        "    x = layers.Dropout(0.5)(x)    \n",
        "\n",
        "else:\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(1024, activation = 'relu', kernel_regularizer = regularizers.l2(0.01),)(x) \n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "predictions = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "if self_sup == True:\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    \n",
        "    model.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    \n",
        "    if aug == True:\n",
        "        hist = model.fit_generator(train_generator, epochs=30, validation_data=test_generator, callbacks=[cp], verbose=1)\n",
        "    else:\n",
        "        hist1 = model.fit(x=train_img,y = y_train, epochs=30, validation_data=(test_img, y_test), callbacks=[cp], verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/30\n",
            "17/17 [==============================] - 185s 11s/step - loss: 14.2537 - accuracy: 0.4816 - val_loss: 16.6655 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 16.66549, saving model to 50Exp2_full_run1.hdf5\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 2s 120ms/step - loss: 13.7181 - accuracy: 0.5165 - val_loss: 17.2690 - val_accuracy: 0.5123\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 16.66549\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 3s 155ms/step - loss: 13.2877 - accuracy: 0.5368 - val_loss: 17.2765 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 16.66549\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 3s 158ms/step - loss: 12.8397 - accuracy: 0.5754 - val_loss: 24.4769 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 16.66549\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 3s 161ms/step - loss: 12.4792 - accuracy: 0.5643 - val_loss: 29.6751 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 16.66549\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 12.0732 - accuracy: 0.5928 - val_loss: 24.7128 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 16.66549\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 11.6608 - accuracy: 0.6131 - val_loss: 20.6601 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 16.66549\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 3s 162ms/step - loss: 11.3051 - accuracy: 0.6296 - val_loss: 22.3064 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 16.66549\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 3s 157ms/step - loss: 10.9373 - accuracy: 0.6333 - val_loss: 37.7978 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 16.66549\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 10.5409 - accuracy: 0.6765 - val_loss: 25.5110 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 16.66549\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 10.2211 - accuracy: 0.6774 - val_loss: 25.1534 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 16.66549\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 9.8802 - accuracy: 0.6875 - val_loss: 38.0568 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 16.66549\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 3s 155ms/step - loss: 9.5237 - accuracy: 0.7243 - val_loss: 25.8858 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 16.66549\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 3s 160ms/step - loss: 9.1935 - accuracy: 0.7270 - val_loss: 37.1886 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 16.66549\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 3s 159ms/step - loss: 8.9032 - accuracy: 0.7270 - val_loss: 27.2402 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 16.66549\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 3s 157ms/step - loss: 8.5825 - accuracy: 0.7463 - val_loss: 66.3474 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 16.66549\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 3s 153ms/step - loss: 8.3053 - accuracy: 0.7491 - val_loss: 40.8190 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 16.66549\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 3s 159ms/step - loss: 8.0111 - accuracy: 0.7675 - val_loss: 27.5630 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 16.66549\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 3s 155ms/step - loss: 7.7343 - accuracy: 0.7739 - val_loss: 52.5164 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 16.66549\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 3s 158ms/step - loss: 7.4740 - accuracy: 0.7693 - val_loss: 32.3980 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 16.66549\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 7.1950 - accuracy: 0.8015 - val_loss: 32.9744 - val_accuracy: 0.5025\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 16.66549\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 3s 160ms/step - loss: 6.9720 - accuracy: 0.7831 - val_loss: 10.2916 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00022: val_loss improved from 16.66549 to 10.29155, saving model to 50Exp2_full_run1.hdf5\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 3s 151ms/step - loss: 6.7158 - accuracy: 0.8097 - val_loss: 40.7257 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 10.29155\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 3s 155ms/step - loss: 6.5001 - accuracy: 0.8033 - val_loss: 38.1072 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 10.29155\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 3s 158ms/step - loss: 6.2474 - accuracy: 0.8447 - val_loss: 44.2136 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 10.29155\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 3s 159ms/step - loss: 6.0501 - accuracy: 0.8318 - val_loss: 62.1164 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 10.29155\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 3s 157ms/step - loss: 5.8285 - accuracy: 0.8401 - val_loss: 47.6112 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 10.29155\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 3s 157ms/step - loss: 5.6376 - accuracy: 0.8428 - val_loss: 49.5477 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 10.29155\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 3s 158ms/step - loss: 5.4334 - accuracy: 0.8557 - val_loss: 92.3021 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 10.29155\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 3s 157ms/step - loss: 5.2310 - accuracy: 0.8704 - val_loss: 79.5448 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 10.29155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRO-_A-CZbmG"
      },
      "source": [
        "if self_sup == True:\n",
        "    cp2 = ModelCheckpoint(filepath= file_name + '_run2.hdf5', verbose=1, monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VaKWgu8-nQi",
        "outputId": "dbe577b4-d63f-44c4-c595-0da1f0fdb6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "if aug == True:\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        self_frac + 'train',\n",
        "        target_size = (W,H),\n",
        "        batch_size = 4,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        self_frac + 'test',\n",
        "        target_size = (W,H),\n",
        "        #batch_size = 16,\n",
        "        class_mode = 'categorical'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 544 images belonging to 2 classes.\n",
            "Found 204 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXzQOD_QPu0z",
        "outputId": "75f891ce-1c72-4135-ac3e-35ba9013786e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if self_sup == True:\n",
        "    #Fine tuning\n",
        "\n",
        "    from keras.models import load_model\n",
        "    model = load_model(file_name + '_run1.hdf5')\n",
        "\n",
        "\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "    \n",
        "    from keras.optimizers import SGD\n",
        "    model.compile(optimizer=SGD(lr=0.00001, momentum=0.9), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    \n",
        "    if aug == True:\n",
        "        hist = model.fit_generator(train_generator, epochs=30, validation_data=test_generator, callbacks=[cp2], verbose=1)\n",
        "    else:\n",
        "        hist1 = model.fit(x=train_img,y = y_train, epochs=30, validation_data=(test_img, y_test), callbacks=[cp2], verbose=1)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 22s 161ms/step - loss: 7.1254 - accuracy: 0.5680 - val_loss: 7.4362 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 7.43625, saving model to 50Exp2_full_run2.hdf5\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 7.1418 - accuracy: 0.5607 - val_loss: 7.0307 - val_accuracy: 0.5196\n",
            "\n",
            "Epoch 00002: val_loss improved from 7.43625 to 7.03070, saving model to 50Exp2_full_run2.hdf5\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 7.1468 - accuracy: 0.5662 - val_loss: 7.1897 - val_accuracy: 0.5245\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 7.03070\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 7.1085 - accuracy: 0.5616 - val_loss: 7.0959 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 7.03070\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 7.1002 - accuracy: 0.5910 - val_loss: 7.1123 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 7.03070\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 7.0926 - accuracy: 0.5901 - val_loss: 7.1451 - val_accuracy: 0.5221\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 7.03070\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 7.0697 - accuracy: 0.6048 - val_loss: 7.0186 - val_accuracy: 0.5196\n",
            "\n",
            "Epoch 00007: val_loss improved from 7.03070 to 7.01864, saving model to 50Exp2_full_run2.hdf5\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 7.0484 - accuracy: 0.6039 - val_loss: 6.8958 - val_accuracy: 0.5270\n",
            "\n",
            "Epoch 00008: val_loss improved from 7.01864 to 6.89579, saving model to 50Exp2_full_run2.hdf5\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 7.0411 - accuracy: 0.6176 - val_loss: 6.9867 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 6.89579\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 7.0618 - accuracy: 0.6176 - val_loss: 7.3678 - val_accuracy: 0.5392\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 6.89579\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 7.0015 - accuracy: 0.6406 - val_loss: 6.9425 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 6.89579\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 7.0025 - accuracy: 0.6406 - val_loss: 6.9574 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 6.89579\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9952 - accuracy: 0.6544 - val_loss: 6.8262 - val_accuracy: 0.5270\n",
            "\n",
            "Epoch 00013: val_loss improved from 6.89579 to 6.82623, saving model to 50Exp2_full_run2.hdf5\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9644 - accuracy: 0.6618 - val_loss: 6.9977 - val_accuracy: 0.5392\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 6.82623\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 6.9448 - accuracy: 0.6774 - val_loss: 7.1965 - val_accuracy: 0.5221\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 6.82623\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 6.9161 - accuracy: 0.6866 - val_loss: 7.6207 - val_accuracy: 0.5343\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 6.82623\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9386 - accuracy: 0.6746 - val_loss: 6.9289 - val_accuracy: 0.5662\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 6.82623\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9302 - accuracy: 0.6838 - val_loss: 7.2892 - val_accuracy: 0.5270\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 6.82623\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.8809 - accuracy: 0.7160 - val_loss: 7.1268 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 6.82623\n",
            "Epoch 20/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.8585 - accuracy: 0.7445 - val_loss: 7.4189 - val_accuracy: 0.5343\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 6.82623\n",
            "Epoch 21/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.8798 - accuracy: 0.6958 - val_loss: 6.9830 - val_accuracy: 0.5074\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 6.82623\n",
            "Epoch 22/30\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 6.8880 - accuracy: 0.7031 - val_loss: 7.0500 - val_accuracy: 0.5343\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 6.82623\n",
            "Epoch 23/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.8448 - accuracy: 0.7252 - val_loss: 7.0274 - val_accuracy: 0.5588\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 6.82623\n",
            "Epoch 24/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.8424 - accuracy: 0.7261 - val_loss: 6.8723 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 6.82623\n",
            "Epoch 25/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.8843 - accuracy: 0.6903 - val_loss: 7.1416 - val_accuracy: 0.5662\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 6.82623\n",
            "Epoch 26/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.8298 - accuracy: 0.7362 - val_loss: 7.0560 - val_accuracy: 0.6201\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 6.82623\n",
            "Epoch 27/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.7993 - accuracy: 0.7436 - val_loss: 7.0077 - val_accuracy: 0.5956\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 6.82623\n",
            "Epoch 28/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.7832 - accuracy: 0.7675 - val_loss: 6.8533 - val_accuracy: 0.5735\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 6.82623\n",
            "Epoch 29/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.7668 - accuracy: 0.7675 - val_loss: 7.0011 - val_accuracy: 0.5882\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 6.82623\n",
            "Epoch 30/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.7753 - accuracy: 0.7518 - val_loss: 7.1987 - val_accuracy: 0.5931\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 6.82623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEUHa08490On"
      },
      "source": [
        "if self_sup == True:\n",
        "    #learning rate decay\n",
        "    \n",
        "    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "    cp3 = ModelCheckpoint(filepath=file_name + '_run3.hdf5', verbose=1, monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCPO7ly9bBD4",
        "outputId": "7c89f000-e0cd-4526-e624-a9f76673e857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if self_sup == True:\n",
        "    model = load_model(file_name + '_run2.hdf5')\n",
        "    model.compile(optimizer=SGD(lr=0.000001), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    \n",
        "    if aug == True:\n",
        "        hist = model.fit_generator(train_generator, epochs=30, validation_data=test_generator, callbacks=[cp3], verbose=1)\n",
        "    else:\n",
        "        hist1 = model.fit(x=train_img,y = y_train, epochs=30, validation_data=(test_img, y_test), callbacks=[cp3], verbose=1)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 22s 165ms/step - loss: 6.9482 - accuracy: 0.6765 - val_loss: 7.2180 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 7.21804, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9764 - accuracy: 0.6507 - val_loss: 7.0938 - val_accuracy: 0.5025\n",
            "\n",
            "Epoch 00002: val_loss improved from 7.21804 to 7.09384, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9536 - accuracy: 0.6654 - val_loss: 7.0295 - val_accuracy: 0.5074\n",
            "\n",
            "Epoch 00003: val_loss improved from 7.09384 to 7.02947, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9585 - accuracy: 0.6719 - val_loss: 7.3419 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 7.02947\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9484 - accuracy: 0.6838 - val_loss: 7.0133 - val_accuracy: 0.5098\n",
            "\n",
            "Epoch 00005: val_loss improved from 7.02947 to 7.01327, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9834 - accuracy: 0.6544 - val_loss: 7.1010 - val_accuracy: 0.5221\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 7.01327\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9565 - accuracy: 0.6783 - val_loss: 7.1624 - val_accuracy: 0.5025\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 7.01327\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 6.9892 - accuracy: 0.6517 - val_loss: 7.2950 - val_accuracy: 0.5147\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 7.01327\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9629 - accuracy: 0.6599 - val_loss: 7.2017 - val_accuracy: 0.5196\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 7.01327\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9461 - accuracy: 0.6783 - val_loss: 7.1585 - val_accuracy: 0.5098\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 7.01327\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9693 - accuracy: 0.6645 - val_loss: 6.9617 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00011: val_loss improved from 7.01327 to 6.96167, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9622 - accuracy: 0.6958 - val_loss: 7.1723 - val_accuracy: 0.5074\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 6.96167\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9895 - accuracy: 0.6452 - val_loss: 7.3382 - val_accuracy: 0.5098\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 6.96167\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9590 - accuracy: 0.6599 - val_loss: 7.0242 - val_accuracy: 0.5098\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 6.96167\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9551 - accuracy: 0.6875 - val_loss: 7.2509 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 6.96167\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9773 - accuracy: 0.6498 - val_loss: 7.1298 - val_accuracy: 0.5074\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 6.96167\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9717 - accuracy: 0.6618 - val_loss: 7.2358 - val_accuracy: 0.5245\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 6.96167\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9650 - accuracy: 0.6636 - val_loss: 7.0702 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 6.96167\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9509 - accuracy: 0.6774 - val_loss: 7.1691 - val_accuracy: 0.5123\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 6.96167\n",
            "Epoch 20/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9477 - accuracy: 0.6792 - val_loss: 7.3023 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 6.96167\n",
            "Epoch 21/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9523 - accuracy: 0.6682 - val_loss: 7.5229 - val_accuracy: 0.5098\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 6.96167\n",
            "Epoch 22/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9592 - accuracy: 0.6562 - val_loss: 7.0002 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 6.96167\n",
            "Epoch 23/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9684 - accuracy: 0.6553 - val_loss: 7.0909 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 6.96167\n",
            "Epoch 24/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9551 - accuracy: 0.6866 - val_loss: 7.2509 - val_accuracy: 0.5123\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 6.96167\n",
            "Epoch 25/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9630 - accuracy: 0.6599 - val_loss: 7.2539 - val_accuracy: 0.5221\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 6.96167\n",
            "Epoch 26/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9332 - accuracy: 0.6801 - val_loss: 7.1004 - val_accuracy: 0.5319\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 6.96167\n",
            "Epoch 27/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9354 - accuracy: 0.6921 - val_loss: 6.9434 - val_accuracy: 0.5196\n",
            "\n",
            "Epoch 00027: val_loss improved from 6.96167 to 6.94341, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 28/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 6.9713 - accuracy: 0.6627 - val_loss: 6.8236 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00028: val_loss improved from 6.94341 to 6.82364, saving model to 50Exp2_full_run3.hdf5\n",
            "Epoch 29/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 6.9166 - accuracy: 0.6985 - val_loss: 6.8888 - val_accuracy: 0.5074\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 6.82364\n",
            "Epoch 30/30\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 6.9378 - accuracy: 0.6801 - val_loss: 7.1804 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 6.82364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFFXAfOpWQ_C"
      },
      "source": [
        "#Try on benign vs malignant\n",
        "os.chdir('/content/drive/My Drive/MRP/Covid-target/organized/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APeHNWJh06sU"
      },
      "source": [
        "org_base = '/content/drive/My Drive/MRP/Covid-target/self/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYeHgmhZdtep"
      },
      "source": [
        "lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "cp4 = ModelCheckpoint(filepath=file_name + '_run4.hdf5', verbose=1, monitor='val_accuracy', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCA63IhiAah3",
        "outputId": "0fd676df-a811-46a4-8749-c94a89ad60d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "if aug == True:\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        'big_train',\n",
        "        target_size = (W,H),\n",
        "        #batch_size = 32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size = (W,H),\n",
        "        #batch_size = 16,\n",
        "        class_mode = 'categorical'\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 543 images belonging to 2 classes.\n",
            "Found 203 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDh2bgr2eqEc",
        "outputId": "e5eca526-b265-4417-c3de-b221997c9d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#benign vs malignant\n",
        "if self_sup == True:\n",
        "    model = load_model(org_base + file_name + '_run3.hdf5')\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "if aug == True:\n",
        "    hist = model.fit_generator(train_generator, epochs=30, validation_data=test_generator, callbacks=[cp4], verbose=1)\n",
        "else:\n",
        "    hist1 = model.fit(x=train_img,y = y_train, epochs=30, validation_data=(test_img, y_test), callbacks=[cp4], verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "17/17 [==============================] - 152s 9s/step - loss: 6.7916 - accuracy: 0.7192 - val_loss: 6.6142 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83005, saving model to 50Exp2_full_run4.hdf5\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 5.9794 - accuracy: 0.9834 - val_loss: 6.6967 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.83005 to 0.83251, saving model to 50Exp2_full_run4.hdf5\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 5s 322ms/step - loss: 5.5186 - accuracy: 0.9963 - val_loss: 6.4887 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.83251\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 5s 322ms/step - loss: 4.9262 - accuracy: 1.0000 - val_loss: 5.9685 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.83251\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 4.3542 - accuracy: 0.9843 - val_loss: 4.3766 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.83251\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 3.8632 - accuracy: 0.9890 - val_loss: 5.4357 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.83251\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 3.3970 - accuracy: 0.9945 - val_loss: 3.4556 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.83251\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 3.0210 - accuracy: 0.9733 - val_loss: 3.7247 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.83251\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 5s 322ms/step - loss: 2.6984 - accuracy: 0.9890 - val_loss: 2.5180 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.83251 to 0.84975, saving model to 50Exp2_full_run4.hdf5\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 2.4083 - accuracy: 0.9834 - val_loss: 2.9616 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.84975\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 2.1232 - accuracy: 0.9972 - val_loss: 4.6120 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.84975\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 1.8231 - accuracy: 1.0000 - val_loss: 3.2516 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.84975\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 1.5313 - accuracy: 0.9972 - val_loss: 2.0828 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.84975\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 1.2554 - accuracy: 0.9982 - val_loss: 2.2504 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.84975\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 1.0260 - accuracy: 0.9991 - val_loss: 2.4700 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.84975\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.8914 - accuracy: 0.9770 - val_loss: 1.5401 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.84975\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.7489 - accuracy: 0.9936 - val_loss: 1.6966 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.84975\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.6779 - accuracy: 0.9843 - val_loss: 1.4710 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84975\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.5925 - accuracy: 0.9908 - val_loss: 2.4989 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.84975\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.4887 - accuracy: 1.0000 - val_loss: 1.6022 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.84975\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.4088 - accuracy: 0.9945 - val_loss: 1.1503 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.84975\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.3267 - accuracy: 0.9972 - val_loss: 1.5680 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84975\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.2607 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.84975\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.2043 - accuracy: 0.9963 - val_loss: 1.4267 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84975\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.1768 - accuracy: 0.9926 - val_loss: 1.2173 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84975\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.1380 - accuracy: 0.9963 - val_loss: 0.6911 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84975\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.1400 - accuracy: 0.9843 - val_loss: 2.2328 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84975\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.1135 - accuracy: 0.9963 - val_loss: 2.0084 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84975\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 5s 322ms/step - loss: 0.1056 - accuracy: 0.9926 - val_loss: 1.5537 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84975\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.0899 - accuracy: 0.9963 - val_loss: 1.5892 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhgaI5A5-5mb",
        "outputId": "747d0fce-4097-4a8e-d712-935ca7131a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "if aug == True:\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        'big_train',     # changed to big_train. if 425 is fisrst number below, this needs to be re run.\n",
        "        target_size = (W,H),\n",
        "        batch_size = 4,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size = (W,H),\n",
        "        #batch_size = 16,\n",
        "        class_mode = 'categorical'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 543 images belonging to 2 classes.\n",
            "Found 203 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6Aj6VO6srs"
      },
      "source": [
        "cp5 = ModelCheckpoint(filepath=file_name + '_run5.hdf5', verbose=1, monitor='val_accuracy', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoWZT1o7ZdxV",
        "outputId": "1eaac3a7-447b-4263-96ec-cc61970d8984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model = load_model(file_name + '_run4.hdf5')\n",
        "for layer in model.layers:\n",
        "   layer.trainable = True\n",
        "\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.00001, momentum=0.9), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "if aug == True:\n",
        "    hist = model.fit_generator(train_generator, epochs=30, validation_data=test_generator, callbacks=[cp5], verbose=1)\n",
        "else:\n",
        "    hist1 = model.fit(x=train_img,y = y_train, epochs=30, validation_data=(test_img, y_test), verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 24s 180ms/step - loss: 0.5689 - accuracy: 0.8987 - val_loss: 0.5095 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.84729, saving model to 50Exp2_full_run5.hdf5\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 12s 91ms/step - loss: 0.4172 - accuracy: 0.9227 - val_loss: 0.3277 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.84729 to 0.86207, saving model to 50Exp2_full_run5.hdf5\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 12s 90ms/step - loss: 0.4168 - accuracy: 0.9190 - val_loss: 0.5545 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.86207\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.4224 - accuracy: 0.9125 - val_loss: 0.7651 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.86207\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.4940 - accuracy: 0.8959 - val_loss: 0.2909 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.86207\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3335 - accuracy: 0.9282 - val_loss: 1.6425 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.86207\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3729 - accuracy: 0.9328 - val_loss: 0.1537 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.86207\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3209 - accuracy: 0.9429 - val_loss: 1.6343 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.86207\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 0.4762 - accuracy: 0.8895 - val_loss: 1.0580 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.86207\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.4348 - accuracy: 0.9116 - val_loss: 0.3100 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.86207\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3065 - accuracy: 0.9088 - val_loss: 0.5981 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.86207\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 0.2796 - accuracy: 0.9411 - val_loss: 0.0757 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.86207\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.4167 - accuracy: 0.9061 - val_loss: 0.5935 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.86207\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 0.3871 - accuracy: 0.9079 - val_loss: 0.4195 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.86207\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3123 - accuracy: 0.9171 - val_loss: 1.0699 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.86207\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3013 - accuracy: 0.9328 - val_loss: 0.4919 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.86207\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3933 - accuracy: 0.8996 - val_loss: 0.4557 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.86207\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3344 - accuracy: 0.9180 - val_loss: 0.2230 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.86207\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3531 - accuracy: 0.9134 - val_loss: 1.1496 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.86207\n",
            "Epoch 20/30\n",
            "136/136 [==============================] - 12s 87ms/step - loss: 0.2977 - accuracy: 0.9171 - val_loss: 0.1058 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.86207\n",
            "Epoch 21/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3414 - accuracy: 0.9070 - val_loss: 1.1179 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.86207\n",
            "Epoch 22/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 0.2740 - accuracy: 0.9374 - val_loss: 0.8127 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.86207\n",
            "Epoch 23/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 1.0051 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.86207\n",
            "Epoch 24/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.2396 - accuracy: 0.9365 - val_loss: 0.4009 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86207\n",
            "Epoch 25/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.2712 - accuracy: 0.9263 - val_loss: 0.6874 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86207\n",
            "Epoch 26/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.2757 - accuracy: 0.9374 - val_loss: 0.4208 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86207\n",
            "Epoch 27/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 0.2755 - accuracy: 0.9365 - val_loss: 0.0909 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86207\n",
            "Epoch 28/30\n",
            "136/136 [==============================] - 12s 89ms/step - loss: 0.2238 - accuracy: 0.9365 - val_loss: 0.7771 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86207\n",
            "Epoch 29/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.3068 - accuracy: 0.9208 - val_loss: 0.3938 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86207\n",
            "Epoch 30/30\n",
            "136/136 [==============================] - 12s 88ms/step - loss: 0.2654 - accuracy: 0.9383 - val_loss: 0.9404 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.86207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WKSF0iDc5CU",
        "outputId": "b381a926-5804-43b9-f775-10f0e73c42b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "total_time = time.clock() - start_time\n",
        "print(total_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2719.6700220000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyP7GH1mkdbV"
      },
      "source": [
        "model = load_model(file_name + '_run5.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMsjCk6iE-GT",
        "outputId": "4ce86483-30bd-4962-dba6-eab1ae9d74df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "generator = test_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size=(W, H),\n",
        "        batch_size=1,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)  # keep data in same order as labels\n",
        "\n",
        "probabilities = model.predict_generator(generator, 203)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 203 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r96QAcJJi9IE",
        "outputId": "bf87e167-c779-4a09-a5e0-44ae49d84a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "y_true = np.array([0] * 98 + [1] * 105)\n",
        "y_pred = np.argmax(probabilities, axis = 1)\n",
        "\n",
        "confusion_matrix(y_true, y_pred.round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[82, 16],\n",
              "       [12, 93]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PsIF9zJjoaN",
        "outputId": "96cd4a2f-9b7b-4ff4-8e85-ddf4eace503b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(f1_score(y_true, y_pred))\n",
        "print()\n",
        "print(roc_auc_score(y_true, y_pred))\n",
        "print()\n",
        "print(accuracy_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8691588785046729\n",
            "\n",
            "0.8612244897959185\n",
            "\n",
            "0.8620689655172413\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
